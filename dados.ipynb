{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a6708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bootstrap] executando: /Users/macvini/Library/CloudStorage/OneDrive-Pessoal/Repos/disserta_dados/.venv/bin/python -m pip install --disable-pip-version-check --no-input -r requirements.txt\n",
      "Requirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: comm==0.2.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (0.2.3)\n",
      "Requirement already satisfied: contourpy==1.3.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler==0.12.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.16 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (1.8.16)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: fonttools==4.59.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (4.59.1)\n",
      "Requirement already satisfied: ipykernel==6.30.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 10)) (6.30.1)\n",
      "Requirement already satisfied: ipython==9.4.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 11)) (9.4.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 12)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 13)) (0.19.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 14)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.8.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 15)) (5.8.1)\n",
      "Requirement already satisfied: kiwisolver==1.4.9 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 16)) (1.4.9)\n",
      "Requirement already satisfied: matplotlib==3.10.5 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 17)) (3.10.5)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 18)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 19)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.3.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 20)) (2.3.2)\n",
      "Requirement already satisfied: packaging==25.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 21)) (25.0)\n",
      "Requirement already satisfied: pandas==2.3.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 22)) (2.3.1)\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 23)) (0.8.4)\n",
      "Requirement already satisfied: patsy==1.0.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 24)) (1.0.1)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 25)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.3.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 26)) (11.3.0)\n",
      "Requirement already satisfied: platformdirs==4.3.8 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 27)) (4.3.8)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.51 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 28)) (3.0.51)\n",
      "Requirement already satisfied: psutil==7.0.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 29)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 30)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 31)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 32)) (2.19.2)\n",
      "Requirement already satisfied: pyparsing==3.2.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 33)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 34)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 35)) (2025.2)\n",
      "Requirement already satisfied: pyzmq==27.0.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 36)) (27.0.1)\n",
      "Requirement already satisfied: scipy==1.16.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 37)) (1.16.1)\n",
      "Requirement already satisfied: seaborn==0.13.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 38)) (0.13.2)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 39)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 40)) (0.6.3)\n",
      "Requirement already satisfied: statsmodels==0.14.5 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 41)) (0.14.5)\n",
      "Requirement already satisfied: tornado==6.5.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 42)) (6.5.2)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 43)) (5.14.3)\n",
      "Requirement already satisfied: tzdata==2025.2 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 44)) (2025.2)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 45)) (0.2.13)\n",
      "Requirement already satisfied: pyreadstat==1.3.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 46)) (1.3.1)\n",
      "Requirement already satisfied: linearmodels==6.1 in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 47)) (6.1)\n",
      "Requirement already satisfied: narwhals>=2.0 in ./.venv/lib/python3.13/site-packages (from pyreadstat==1.3.1->-r requirements.txt (line 46)) (2.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4 in ./.venv/lib/python3.13/site-packages (from linearmodels==6.1->-r requirements.txt (line 47)) (1.1.0)\n",
      "Requirement already satisfied: Cython>=3.0.10 in ./.venv/lib/python3.13/site-packages (from linearmodels==6.1->-r requirements.txt (line 47)) (3.1.3)\n",
      "Requirement already satisfied: pyhdfe>=0.1 in ./.venv/lib/python3.13/site-packages (from linearmodels==6.1->-r requirements.txt (line 47)) (0.2.0)\n",
      "Requirement already satisfied: formulaic>=1.0.0 in ./.venv/lib/python3.13/site-packages (from linearmodels==6.1->-r requirements.txt (line 47)) (1.2.0)\n",
      "Requirement already satisfied: setuptools-scm<9.0.0,>=8.0.0 in ./.venv/lib/python3.13/site-packages (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels==6.1->-r requirements.txt (line 47)) (8.3.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels==6.1->-r requirements.txt (line 47)) (80.9.0)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in ./.venv/lib/python3.13/site-packages (from formulaic>=1.0.0->linearmodels==6.1->-r requirements.txt (line 47)) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.13/site-packages (from formulaic>=1.0.0->linearmodels==6.1->-r requirements.txt (line 47)) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.17.0rc1 in ./.venv/lib/python3.13/site-packages (from formulaic>=1.0.0->linearmodels==6.1->-r requirements.txt (line 47)) (2.0.0rc2)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Análise de Painel - Dissertação (Python vs Stata)\n",
    "Requisitos (pip): pandas, numpy, matplotlib, pyreadstat, linearmodels, scipy, statsmodels, seaborn (opcional para gráficos)\n",
    "\"\"\"\n",
    "import bootstrap_deps as deps\n",
    "deps.ensure(requirements_file=\"requirements.txt\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# opcional (para gráficos mais bonitos; remova se preferir apenas matplotlib)\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except Exception:\n",
    "    sns = None\n",
    "\n",
    "from pyreadstat import read_sas7bdat\n",
    "from scipy.stats import mstats\n",
    "from linearmodels.panel import PanelOLS, RandomEffects, PooledOLS\n",
    "from scipy.stats import chi2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 180)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# ------------------------------\n",
    "# Configuração\n",
    "# ------------------------------\n",
    "INPUT_PATH = r\"/Users/macvini/Library/CloudStorage/OneDrive-Pessoal/Mestrado/base_final_mestrado.sas7bdat\"\n",
    "RESULTS_DIR = \"./resultados_python\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Utils\n",
    "# ------------------------------\n",
    "def slug(s: str) -> str:\n",
    "    \"\"\"Normaliza nomes de colunas (sem acentos/símbolos), em minúsculas e com underscores.\"\"\"\n",
    "    if s is None:\n",
    "        return \"col\"\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFKD', str(s)) if not unicodedata.combining(c))\n",
    "    s = re.sub(r'[^0-9a-zA-Z_]+', '_', s).strip('_').lower()\n",
    "    return s or \"col\"\n",
    "\n",
    "\n",
    "def winsorize_series(s: pd.Series, limits=(0.01, 0.01)) -> pd.Series:\n",
    "    \"\"\"Winsoriza série preservando índice e dtype float; ignora NaNs.\"\"\"\n",
    "    s2 = s.astype(float).copy()\n",
    "    mask = s2.notna()\n",
    "    if mask.any():\n",
    "        s2.loc[mask] = np.asarray(mstats.winsorize(s2.loc[mask].values, limits=limits), dtype=float)\n",
    "    return s2.astype(float)\n",
    "\n",
    "\n",
    "def hausman(fe_res, re_res):\n",
    "    \"\"\"Teste de Hausman entre FE e RE (aproximação).\"\"\"\n",
    "    b = fe_res.params\n",
    "    B = re_res.params.reindex_like(b)\n",
    "    common = b.dropna().index.intersection(B.dropna().index)\n",
    "    b = b.loc[common]; B = B.loc[common]\n",
    "    Vb = fe_res.cov.loc[common, common]\n",
    "    VB = re_res.cov.loc[common, common]\n",
    "    diff = (b - B).values.reshape(-1,1)\n",
    "    V = (Vb - VB).values\n",
    "    try:\n",
    "        stat = float(diff.T @ np.linalg.pinv(V) @ diff)\n",
    "    except Exception:\n",
    "        return np.nan, len(common), np.nan\n",
    "    dof_ = len(common)\n",
    "    pval = 1 - chi2.cdf(stat, dof_)\n",
    "    return stat, dof_, pval\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Importação\n",
    "# ------------------------------\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    df, meta = read_sas7bdat(path, encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Preparação & Engenharia\n",
    "# ------------------------------\n",
    "def prepare_engineer(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Excluir linhas com missing/vazio para 'cliente' e criar id_cliente\n",
    "    if 'cliente' in df.columns:\n",
    "        df = df.dropna(subset=['cliente'])\n",
    "        df = df[df['cliente'] != '']\n",
    "        df['id_cliente'] = df.groupby('cliente').ngroup()\n",
    "    else:\n",
    "        raise KeyError(\"Coluna 'cliente' não encontrada.\")\n",
    "\n",
    "    # Data de nascimento -> idade\n",
    "    if 'DT_NASCIMENTO' in df.columns:\n",
    "        df['DT_NASCIMENTO'] = pd.to_datetime('1960-01-01') + pd.to_timedelta(df['DT_NASCIMENTO'], unit='D')\n",
    "        hoje = pd.to_datetime('today').normalize()\n",
    "        df['idade'] = (hoje - df['DT_NASCIMENTO']).dt.days / 365.25\n",
    "        df['idade_int'] = df['idade'].astype(int)\n",
    "    else:\n",
    "        df['idade_int'] = np.nan\n",
    "\n",
    "    # Investimento exterior consolidado\n",
    "    colunas_invest_ext = [c for c in [\n",
    "        'INVEST_EXT_RENDA_VARIAVEL', 'INVEST_NO_EXTERIOR', 'INVEST_EXTERIOR', 'INVEST_EXT_RENDA_FIXA'\n",
    "    ] if c in df.columns]\n",
    "    df['investimento_exterior'] = df[colunas_invest_ext].sum(axis=1, skipna=True) if colunas_invest_ext else 0.0\n",
    "\n",
    "    # Sexo dummy (float)\n",
    "    if 'SEXO' in df.columns:\n",
    "        df['sexo_dummy'] = df['SEXO'].map({'M': 1, 'F': 0}).astype(float)\n",
    "    else:\n",
    "        df['sexo_dummy'] = np.nan\n",
    "\n",
    "    # Regiões (nomes com underscore)\n",
    "    regioes = {\n",
    "        'norte': [\"AC\", \"AP\", \"AM\", \"PA\", \"RO\", \"RR\", \"TO\"],\n",
    "        'nordeste': [\"AL\", \"BA\", \"CE\", \"MA\", \"PB\", \"PE\", \"PI\", \"RN\", \"SE\"],\n",
    "        'sudeste': [\"ES\", \"MG\", \"RJ\", \"SP\"],\n",
    "        'sul': [\"PR\", \"RS\", \"SC\"],\n",
    "        'centro_oeste': [\"DF\", \"GO\", \"MT\", \"MS\"],\n",
    "    }\n",
    "    if 'UF_CADASTRO' in df.columns:\n",
    "        for regiao, ufs in regioes.items():\n",
    "            df[f'regiao_{regiao}'] = df['UF_CADASTRO'].isin(ufs).astype(int)\n",
    "        reg_cols = ['regiao_norte', 'regiao_nordeste', 'regiao_sudeste', 'regiao_sul', 'regiao_centro_oeste']\n",
    "        df['regiao_codigo'] = df[reg_cols].dot(pd.Series([1,2,3,4,5], index=reg_cols)).astype(int)\n",
    "    else:\n",
    "        for regiao in ['norte','nordeste','sudeste','sul','centro_oeste']:\n",
    "            df[f'regiao_{regiao}'] = 0\n",
    "        df['regiao_codigo'] = 0\n",
    "\n",
    "    # Estilo investidor\n",
    "    if 'NM_TIP_CTRA' in df.columns:\n",
    "        df['estilo_investidor'] = (df['NM_TIP_CTRA'] == \"ESTILO INVESTIDOR\").astype(int)\n",
    "    else:\n",
    "        df['estilo_investidor'] = 0\n",
    "\n",
    "    # Estado civil -> grupos\n",
    "    if 'EST_CIVIL' in df.columns:\n",
    "        ec_map = {\n",
    "            1: 'solteiro',\n",
    "            2: 'casado', 3: 'casado', 4: 'casado', 8: 'casado', 9: 'casado', 11: 'casado', 12: 'casado',\n",
    "            6: 'separado', 7: 'separado',\n",
    "            5: 'viuvo'\n",
    "        }\n",
    "        df['estado_civil_grupo'] = df['EST_CIVIL'].map(ec_map).fillna('nao_informado')\n",
    "        ec_dum = pd.get_dummies(df['estado_civil_grupo'], prefix='ec', dtype=int)\n",
    "        df = pd.concat([df, ec_dum], axis=1)\n",
    "    else:\n",
    "        df['estado_civil_grupo'] = 'nao_informado'\n",
    "\n",
    "    # Escolaridade -> grupos\n",
    "    if 'ESCOLAR' in df.columns:\n",
    "        esc_map = {\n",
    "            1: 'baixa', 2: 'baixa',\n",
    "            3: 'media', 4: 'media', 9: 'media',\n",
    "            5: 'alta', 6: 'alta', 7: 'alta', 8: 'alta',\n",
    "            0: 'missing'\n",
    "        }\n",
    "        df['escolaridade_grupo'] = df['ESCOLAR'].map(esc_map).fillna('nao_informado')\n",
    "        esc_dum = pd.get_dummies(df['escolaridade_grupo'], prefix='esc', dtype=int)\n",
    "        df = pd.concat([df, esc_dum], axis=1)\n",
    "    else:\n",
    "        df['escolaridade_grupo'] = 'nao_informado'\n",
    "\n",
    "    # Perfil investidor\n",
    "    if 'CD_PRFL_API' in df.columns:\n",
    "        df['prfl_codigo'] = df['CD_PRFL_API'].replace(0, 5)\n",
    "        df['prfl_codigo'] = df['prfl_codigo'].fillna(5).astype(int)\n",
    "        perfil_map = {1: 'conservador', 2: 'moderado', 3: 'arrojado', 4: 'agressivo', 5: 'nao_resp'}\n",
    "        df['perfil_grupo'] = df['prfl_codigo'].map(perfil_map)\n",
    "    else:\n",
    "        df['perfil_grupo'] = 'nao_resp'\n",
    "\n",
    "    # Ocupação (regex)\n",
    "    ocup_map = {\n",
    "        'Administracao': r'ADMINISTRADOR|CONTADOR|ANALISTA|CONSULTOR|ECONOMISTA',\n",
    "        'Servidor_Publico': r'SERVIDOR PUBLICO|DEPUTADO|PREFEITO|SECRETARIO|MAGISTRADO|PROCURADOR',\n",
    "        'Saude': r'MEDICO|ENFERMEIRO|FISIOTERAPEUTA|ODONTOLOGO|FARMACEUTICO|NUTRICIONISTA|FONOAUDIOLOGO|PSICOLOGO|TERAPEUTA',\n",
    "        'Educacao': r'PROFESSOR|ESTUDANTE|ESTAGIARIO|BOLSISTA|PEDAGOGO',\n",
    "        'Autonomo_Comercio': r'COMERCIANTE|AMBULANTE|TAXISTA|VENDEDOR|FEIRANTE|REPRESENTANTE COMERCIAL',\n",
    "        'Agropecuaria': r'AGRICULTOR|PECUARISTA|PESCADOR|AVICULTOR|RURAL|FLORICULTOR|AGRONOMO|AGROPECUARISTA',\n",
    "        'Industrial': r'MECANICO|ELETRICISTA|OPERADOR|CONSTRUCAO|MARCENEIRO|INDUSTRIARIO|SERRALHEIRO|TECNIC',\n",
    "        'Justica': r'ADVOGADO|DELEGADO|DEFENSOR|PROMOTOR|JUIZ|OFICIAL DE JUSTICA|TABELIAO|CARTORIO',\n",
    "        'Seguranca': r'POLICIAL|MILITAR|VIGILANTE|SEGURANCA|BOMBEIRO',\n",
    "        'Cultura_Comunicacao': r'MUSICO|ATOR|ARTESAO|JORNALISTA|ESCULTOR|PUBLICITARIO|FOTOGRAFO|LOCUTOR'\n",
    "    }\n",
    "    df['grupo_ocupacao'] = 'Outros'\n",
    "    if 'DS_OCUPACAO' in df.columns:\n",
    "        for grupo, regex in ocup_map.items():\n",
    "            df.loc[df['DS_OCUPACAO'].str.contains(regex, case=False, na=False), 'grupo_ocupacao'] = grupo\n",
    "\n",
    "    # Guardar rótulos para gráficos\n",
    "    df['grupo_ocupacao_cat'] = df['grupo_ocupacao'].astype('category')\n",
    "    df['perfil_grupo_cat'] = df['perfil_grupo'].astype('category')\n",
    "\n",
    "    # Dummies com nomes slug\n",
    "    oc_dum = pd.get_dummies(df['grupo_ocupacao'], prefix='oc', dtype=int)\n",
    "    oc_dum.columns = [slug(c) for c in oc_dum.columns]\n",
    "    pf_dum = pd.get_dummies(df['perfil_grupo'], prefix='perfil', dtype=int)\n",
    "    pf_dum.columns = [slug(c) for c in pf_dum.columns]\n",
    "    df = pd.concat([df, oc_dum, pf_dum], axis=1)\n",
    "\n",
    "    # Variáveis regionais (valores médios por região)\n",
    "    dados_regionais = {\n",
    "        'regiao_norte':        {'escolaridade': 9.2,  'renda': 2421.7, 'idh': 0.6847, 'pib': 33123},\n",
    "        'regiao_nordeste':     {'escolaridade': 8.3,  'renda': 2078.0, 'idh': 0.6487, 'pib': 25401},\n",
    "        'regiao_sudeste':      {'escolaridade': 10.0, 'renda': 3514.0, 'idh': 0.7537, 'pib': 63327},\n",
    "        'regiao_sul':          {'escolaridade': 10.1, 'renda': 3423.7, 'idh': 0.7563, 'pib': 55942},\n",
    "        'regiao_centro_oeste': {'escolaridade': 10.1, 'renda': 3604.0, 'idh': 0.7533, 'pib': 65651},\n",
    "    }\n",
    "    for var in ['escolaridade_regiao', 'renda_regional', 'idh_regional', 'pib_percapita_regional']:\n",
    "        df[var] = np.nan\n",
    "    for regiao, valores in dados_regionais.items():\n",
    "        mask = df.get(regiao, 0) == 1\n",
    "        df.loc[mask, 'escolaridade_regiao'] = valores['escolaridade']\n",
    "        df.loc[mask, 'renda_regional'] = valores['renda']\n",
    "        df.loc[mask, 'idh_regional'] = valores['idh']\n",
    "        df.loc[mask, 'pib_percapita_regional'] = valores['pib']\n",
    "\n",
    "    # Variáveis dependentes\n",
    "    soma_complex_cols = [c for c in ['MULTIMERCADOS','RENDA_VARIAVEL','INVEST_ALTERNATIVOS','investimento_exterior'] if c in df.columns]\n",
    "    soma_total_cols   = [c for c in ['RENDA_FIXA_POS_CDI','RENDA_FIXA_PRE','RENDA_FIXA_INFLACAO','MULTIMERCADOS','RENDA_VARIAVEL','INVEST_ALTERNATIVOS','investimento_exterior'] if c in df.columns]\n",
    "    df['soma_complex'] = df[soma_complex_cols].sum(axis=1, skipna=True) if soma_complex_cols else 0.0\n",
    "    df['soma_total']   = df[soma_total_cols].sum(axis=1, skipna=True) if soma_total_cols else 0.0\n",
    "    df['diver'] = (df['soma_complex'] / df['soma_total']).replace([np.inf, -np.inf], np.nan).fillna(0.0).clip(upper=1.0)\n",
    "    df['complex'] = (df['soma_complex'] > 0).astype(int)\n",
    "\n",
    "    # Índice de painel\n",
    "    if 'anomes' not in df.columns:\n",
    "        raise KeyError(\"Coluna 'anomes' (YYYYMM) não encontrada.\")\n",
    "    df['anomes'] = pd.to_datetime(df['anomes'].astype(str), format='%Y%m')\n",
    "    df = df.set_index(['id_cliente', 'anomes']).sort_index()\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    # Delta de renda individual e skew proxy\n",
    "    if 'renda' not in df.columns:\n",
    "        raise KeyError(\"Coluna 'renda' (renda individual mensal ou similar) não encontrada.\")\n",
    "    df['log_renda_ind'] = np.log(df['renda'] + 1)\n",
    "    df['delta_y'] = df.groupby(level='id_cliente')['log_renda_ind'].diff()\n",
    "    df['ano'] = df.index.get_level_values('anomes').year\n",
    "    df['delta_y_anual'] = df.groupby(['id_cliente', 'ano'])['delta_y'].transform('mean')\n",
    "    df['media_dy'] = df.groupby(['regiao_codigo', 'ano'])['delta_y_anual'].transform('mean')\n",
    "    df['sd_dy']    = df.groupby(['regiao_codigo', 'ano'])['delta_y_anual'].transform('std')\n",
    "    df['delta_y_pad'] = (df['delta_y_anual'] - df['media_dy']) / df['sd_dy']\n",
    "    df['skew_aux'] = df['delta_y_pad']**3\n",
    "    df['grupo_n']  = df.groupby(['regiao_codigo', 'ano'])['skew_aux'].transform('count')\n",
    "    df['skew']     = df.groupby(['regiao_codigo', 'ano'])['skew_aux'].transform('mean')\n",
    "    df.loc[df['grupo_n'] < 30, 'skew'] = np.nan\n",
    "    df['skew_final'] = df['skew'].where(df['ano'] > 2021)\n",
    "    df['skew_media_regional'] = df.groupby('regiao_codigo')['skew_final'].transform('mean')\n",
    "    df['skew_proxy'] = df['skew'].fillna(df['skew_media_regional'])\n",
    "\n",
    "    # Logs + winsor\n",
    "    df['ln_diver'] = np.log(df['diver'] + 0.01)\n",
    "    df['ln_renda'] = np.log(df['renda_regional'].fillna(1))\n",
    "    df['ln_ESC']   = np.log(df['escolaridade_regiao'].fillna(1))\n",
    "    df['ln_IDH']   = np.log(df['idh_regional'].fillna(1))\n",
    "    df['ln_PIB']   = np.log(df['pib_percapita_regional'].fillna(1))\n",
    "\n",
    "    for var in ['ln_diver', 'ln_renda', 'ln_ESC', 'ln_IDH', 'ln_PIB']:\n",
    "        df[f'{var}_w'] = winsorize_series(df[var])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Modelagem\n",
    "# ------------------------------\n",
    "def run_models(df: pd.DataFrame):\n",
    "    prints = []\n",
    "\n",
    "    # Matriz de correlação (salvar figura)\n",
    "    corr_vars = [c for c in ['ln_diver_w','ln_renda_w','ln_ESC_w','ln_IDH_w','ln_PIB_w','idade_int','sexo_dummy','skew_proxy'] if c in df.columns]\n",
    "    corr = df[corr_vars].corr()\n",
    "    fig_path = os.path.join(RESULTS_DIR, \"matriz_correlacao.png\")\n",
    "    try:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        if sns is not None:\n",
    "            ax = sns.heatmap(corr, annot=True, fmt=\".2f\")\n",
    "        else:\n",
    "            # fallback simples com matplotlib\n",
    "            plt.imshow(corr, interpolation='nearest')\n",
    "            plt.colorbar()\n",
    "            plt.xticks(range(len(corr_vars)), corr_vars, rotation=45, ha='right')\n",
    "            plt.yticks(range(len(corr_vars)), corr_vars)\n",
    "        plt.title('Matriz de Correlação')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_path, dpi=180)\n",
    "        plt.close()\n",
    "        prints.append(f\"[OK] Matriz de correlação salva em: {fig_path}\")\n",
    "    except Exception as e:\n",
    "        prints.append(f\"[WARN] Falha ao salvar matriz de correlação: {e}\")\n",
    "\n",
    "    # Fórmulas\n",
    "    formula_base = 'ln_diver_w ~ ln_renda_w + ln_IDH_w + sexo_dummy + idade_int'\n",
    "\n",
    "    # Pooled\n",
    "    pooled = PooledOLS.from_formula(formula_base, data=df).fit(cov_type='robust')\n",
    "    prints.append(\"\\n[POOLED]\\n\" + str(pooled.summary))\n",
    "\n",
    "    # FE\n",
    "    fe = PanelOLS.from_formula(formula_base + ' + EntityEffects', data=df).fit(cov_type='clustered', cluster_entity=True)\n",
    "    prints.append(\"\\n[FE]\\n\" + str(fe.summary))\n",
    "\n",
    "    # RE\n",
    "    re = RandomEffects.from_formula(formula_base, data=df).fit(cov_type='clustered', cluster_entity=True)\n",
    "    prints.append(\"\\n[RE]\\n\" + str(re.summary))\n",
    "\n",
    "    # Hausman\n",
    "    try:\n",
    "        stat, dof, p = hausman(fe, re)\n",
    "        prints.append(f\"\\n[HAUSMAN] chi2({dof})={stat:.2f}, p={p:.4f}\")\n",
    "    except Exception as e:\n",
    "        prints.append(f\"\\n[HAUSMAN] falhou: {e}\")\n",
    "\n",
    "    # H1\n",
    "    formula_h1 = (\n",
    "        'ln_diver_w ~ complex + ln_ESC_w + ln_renda_w + '\n",
    "        'regiao_norte + regiao_nordeste + regiao_sul + regiao_centro_oeste + '\n",
    "        'sexo_dummy + idade_int + EntityEffects'\n",
    "    )\n",
    "    h1 = PanelOLS.from_formula(formula_h1, data=df).fit(cov_type='clustered', cluster_entity=True)\n",
    "    prints.append(\"\\n[H1/H1a]\\n\" + str(h1.summary))\n",
    "\n",
    "    # H2\n",
    "    formula_h2 = (\n",
    "        'ln_diver_w ~ skew_proxy + ln_ESC_w + ln_renda_w + '\n",
    "        'regiao_norte + regiao_nordeste + regiao_sul + regiao_centro_oeste + '\n",
    "        'sexo_dummy + idade_int + EntityEffects'\n",
    "    )\n",
    "    h2 = PanelOLS.from_formula(formula_h2, data=df).fit(cov_type='clustered', cluster_entity=True)\n",
    "    prints.append(\"\\n[H2]\\n\" + str(h2.summary))\n",
    "\n",
    "    # H3 (alta renda individual)\n",
    "    if 'renda' in df.columns:\n",
    "        df_h3 = df[df['renda'] > 20000]\n",
    "        formula_h3 = (\n",
    "            'ln_diver_w ~ ln_IDH_w + ln_renda_w + ln_ESC_w + '\n",
    "            'regiao_norte + regiao_nordeste + regiao_sul + regiao_centro_oeste + '\n",
    "            'sexo_dummy + idade_int + EntityEffects'\n",
    "        )\n",
    "        h3 = PanelOLS.from_formula(formula_h3, data=df_h3).fit(cov_type='clustered', cluster_entity=True)\n",
    "        prints.append(\"\\n[H3]\\n\" + str(h3.summary))\n",
    "\n",
    "    # Estatísticas descritivas\n",
    "    desc_cols = [c for c in [\n",
    "        'diver','ln_diver_w','ln_renda_w','ln_ESC_w','ln_IDH_w','idade_int','sexo_dummy','complex','skew_proxy',\n",
    "        'perfil_conservador','perfil_moderado','perfil_arrojado'\n",
    "    ] if c in df.columns]\n",
    "    desc = df[desc_cols].describe().T\n",
    "    desc_path = os.path.join(RESULTS_DIR, \"estatisticas_descritivas.csv\")\n",
    "    desc.to_csv(desc_path, encoding='utf-8')\n",
    "    prints.append(f\"\\n[DESCRITIVAS] salvo em: {desc_path}\")\n",
    "\n",
    "    # Gráficos simples (salvar)\n",
    "    try:\n",
    "        if all(c in df.columns for c in ['ln_renda_w', 'ln_diver_w']):\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.scatter(df['ln_renda_w'], df['ln_diver_w'], s=6, alpha=0.3)\n",
    "            # linha de tendência via np.polyfit\n",
    "            m, b = np.polyfit(df['ln_renda_w'].replace([np.inf,-np.inf], np.nan).dropna(),\n",
    "                              df['ln_diver_w'].replace([np.inf,-np.inf], np.nan).dropna(), 1)\n",
    "            xvals = np.linspace(df['ln_renda_w'].min(), df['ln_renda_w'].max(), 200)\n",
    "            plt.plot(xvals, m*xvals + b)\n",
    "            plt.title('Diversificação vs. Renda (winsor)')\n",
    "            plt.xlabel('ln_renda_w')\n",
    "            plt.ylabel('ln_diver_w')\n",
    "            plt.tight_layout()\n",
    "            fig2 = os.path.join(RESULTS_DIR, \"scatter_diver_vs_renda.png\")\n",
    "            plt.savefig(fig2, dpi=160)\n",
    "            plt.close()\n",
    "            prints.append(f\"[OK] Gráfico scatter salvo em: {fig2}\")\n",
    "    except Exception as e:\n",
    "        prints.append(f\"[WARN] Falha ao salvar gráfico scatter: {e}\")\n",
    "\n",
    "    # Boxplots por ocupação/perfil (seaborn se disponível)\n",
    "    try:\n",
    "        if sns is not None and 'grupo_ocupacao_cat' in df.columns:\n",
    "            plt.figure(figsize=(10,5))\n",
    "            sns.boxplot(x='grupo_ocupacao_cat', y='diver', data=df.reset_index())\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.title('Diversificação por Grupo de Ocupação')\n",
    "            plt.tight_layout()\n",
    "            fig3 = os.path.join(RESULTS_DIR, \"boxplot_diver_ocupacao.png\")\n",
    "            plt.savefig(fig3, dpi=160); plt.close()\n",
    "            prints.append(f\"[OK] Boxplot ocupação salvo em: {fig3}\")\n",
    "        if sns is not None and 'perfil_grupo_cat' in df.columns:\n",
    "            plt.figure(figsize=(8,5))\n",
    "            sns.boxplot(x='perfil_grupo_cat', y='diver', data=df.reset_index())\n",
    "            plt.title('Diversificação por Perfil do Investidor')\n",
    "            plt.tight_layout()\n",
    "            fig4 = os.path.join(RESULTS_DIR, \"boxplot_diver_perfil.png\")\n",
    "            plt.savefig(fig4, dpi=160); plt.close()\n",
    "            prints.append(f\"[OK] Boxplot perfil salvo em: {fig4}\")\n",
    "    except Exception as e:\n",
    "        prints.append(f\"[WARN] Falha ao salvar boxplots: {e}\")\n",
    "\n",
    "    # Salvar sumários em arquivo texto\n",
    "    sum_path = os.path.join(RESULTS_DIR, \"sumarios_modelos.txt\")\n",
    "    with open(sum_path, \"w\", encoding=\"utf-8\") as fh:\n",
    "        fh.write(\"\\n\".join(prints))\n",
    "    print(f\"Sumários salvos em: {sum_path}\")\n",
    "    for p in prints:\n",
    "        print(p)\n",
    "\n",
    "    return dict(pooled=pooled, fe=fe, re=re)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Main\n",
    "# ------------------------------\n",
    "def main():\n",
    "    df = load_data(INPUT_PATH)\n",
    "    df = prepare_engineer(df)\n",
    "\n",
    "    # Checagens rápidas\n",
    "    print(\"Total de clientes:\", df.index.get_level_values('id_cliente').nunique())\n",
    "    print(\"Período:\", df.index.get_level_values('anomes').min().date(), \"→\", df.index.get_level_values('anomes').max().date())\n",
    "    print(\"Soma dummies regionais:\\n\", df.filter(regex=r'^regiao_').sum())\n",
    "\n",
    "    run_models(df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
