{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6052e00e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'linearmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyreadstat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_sas7bdat\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Para rodar as regressões de painel\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlinearmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PanelOLS\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlinearmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpanel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PanelOLS, RandomEffects, PooledOLS\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlinearmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpanel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PanelOLS, FamaMacbeth, RandomEffects, PooledOLS\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'linearmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyreadstat import read_sas7bdat\n",
    "\n",
    "# Para rodar as regressões de painel\n",
    "from linearmodels import PanelOLS\n",
    "from linearmodels.panel import PanelOLS, RandomEffects, PooledOLS\n",
    "from linearmodels.panel.model import PanelOLS, FamaMacbeth, RandomEffects, PooledOLS\n",
    "\n",
    "# Para a winsorização\n",
    "from scipy.stats import mstats\n",
    "\n",
    "# Configurações de exibição do Pandas para mostrar todas as colunas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# --- Importar a base de dados ---\n",
    "# Importar base formato .sas7bdat\n",
    "# Substitua o caminho do arquivo pelo seu\n",
    "df, meta = read_sas7bdat(\"/Users/macvini/Library/CloudStorage/OneDrive-Pessoal/Mestrado/base_final_mestrado.sas7bdat\", encoding='utf-8')\n",
    "\n",
    "# Excluir linhas com missing ou valor vazio para 'cliente'\n",
    "df = df.dropna(subset=['cliente'])\n",
    "df = df[df['cliente'] != '']\n",
    "# Criar ID único para o cliente (equivalente ao `egen group` do Stata)\n",
    "df['id_cliente'] = df.groupby('cliente').ngroup()\n",
    "\n",
    "# --- Engenharia de Variáveis ---\n",
    "\n",
    "# Converter a variável de data para um formato datetime do Python\n",
    "# A data no Stata (DT_NASCIMENTO) é o número de dias desde 01/01/1960.\n",
    "# O Stata também usa `mdy(1,1,1960) + DT_NASCIMENTO`, o que é estranho. A conversão mais precisa seria:\n",
    "df['DT_NASCIMENTO'] = pd.to_datetime('1960-01-01') + pd.to_timedelta(df['DT_NASCIMENTO'], unit='D')\n",
    "# Criar variável idade a partir da data de nascimento\n",
    "hoje = pd.to_datetime('today')\n",
    "df['idade'] = (hoje - df['DT_NASCIMENTO']).dt.days / 365.25\n",
    "df['idade_int'] = df['idade'].astype(int)\n",
    "\n",
    "# Unificar investimentos em uma única variável\n",
    "colunas_invest_ext = ['INVEST_EXT_RENDA_VARIAVEL', 'INVEST_NO_EXTERIOR', 'INVEST_EXTERIOR', 'INVEST_EXT_RENDA_FIXA']\n",
    "df['investimento_exterior'] = df[colunas_invest_ext].sum(axis=1, skipna=True)\n",
    "# O comando `rowtotal` do Stata soma apenas valores não nulos. O `sum(axis=1, skipna=True)` faz o mesmo.\n",
    "\n",
    "# Variável dummy para sexo\n",
    "df['sexo_dummy'] = df['SEXO'].map({'M': 1, 'F': 0}).astype(pd.Int64Dtype()) # Usa Int64Dtype para aceitar NaN\n",
    "\n",
    "# Dummies de Região\n",
    "regioes = {\n",
    "    'Norte': [\"AC\", \"AP\", \"AM\", \"PA\", \"RO\", \"RR\", \"TO\"],\n",
    "    'Nordeste': [\"AL\", \"BA\", \"CE\", \"MA\", \"PB\", \"PE\", \"PI\", \"RN\", \"SE\"],\n",
    "    'Sudeste': [\"ES\", \"MG\", \"RJ\", \"SP\"],\n",
    "    'Sul': [\"PR\", \"RS\", \"SC\"],\n",
    "    'Centro-Oeste': [\"DF\", \"GO\", \"MT\", \"MS\"]\n",
    "}\n",
    "for regiao, ufs in regioes.items():\n",
    "    df[f'regiao_{regiao.lower()}'] = df['UF_CADASTRO'].isin(ufs).astype(int)\n",
    "\n",
    "# Dummy para 'Estilo Investidor'\n",
    "df['estilo_investidor'] = (df['NM_TIP_CTRA'] == \"ESTILO INVESTIDOR\").astype(int)\n",
    "\n",
    "# Dummies para Estado Civil\n",
    "ec_map = {\n",
    "    1: 'solteiro',\n",
    "    2: 'casado', 3: 'casado', 4: 'casado', 8: 'casado', 9: 'casado', 11: 'casado', 12: 'casado',\n",
    "    6: 'separado', 7: 'separado',\n",
    "    5: 'viuvo'\n",
    "}\n",
    "df['estado_civil_grupo'] = df['EST_CIVIL'].map(ec_map).fillna('nao_informado')\n",
    "df = pd.get_dummies(df, columns=['estado_civil_grupo'], prefix='ec', dtype=int)\n",
    "\n",
    "# Dummies para Escolaridade\n",
    "esc_map = {\n",
    "    1: 'baixa', 2: 'baixa',\n",
    "    3: 'media', 4: 'media', 9: 'media',\n",
    "    5: 'alta', 6: 'alta', 7: 'alta', 8: 'alta',\n",
    "    0: 'missing'\n",
    "}\n",
    "df['escolaridade_grupo'] = df['ESCOLAR'].map(esc_map).fillna('nao_informado')\n",
    "df = pd.get_dummies(df, columns=['escolaridade_grupo'], prefix='esc', dtype=int)\n",
    "\n",
    "# Dummies para Perfil Investidor\n",
    "df['prfl_codigo'] = df['CD_PRFL_API'].replace(0, 5)\n",
    "df['prfl_codigo'] = df['prfl_codigo'].fillna(5).astype(int)\n",
    "perfil_map = {\n",
    "    1: 'conservador', 2: 'moderado', 3: 'arrojado', 4: 'agressivo', 5: 'nao_resp'\n",
    "}\n",
    "df['perfil_grupo'] = df['prfl_codigo'].map(perfil_map)\n",
    "df = pd.get_dummies(df, columns=['perfil_grupo'], prefix='perfil', dtype=int)\n",
    "\n",
    "# Dummies para Ocupação usando expressões regulares\n",
    "ocup_map = {\n",
    "    'Administração': r'ADMINISTRADOR|CONTADOR|ANALISTA|CONSULTOR|ECONOMISTA',\n",
    "    'Servidor Público': r'SERVIDOR PUBLICO|DEPUTADO|PREFEITO|SECRETARIO|MAGISTRADO|PROCURADOR',\n",
    "    'Saúde': r'MEDICO|ENFERMEIRO|FISIOTERAPEUTA|ODONTOLOGO|FARMACEUTICO|NUTRICIONISTA|FONOAUDIOLOGO|PSICOLOGO|TERAPEUTA',\n",
    "    'Educação': r'PROFESSOR|ESTUDANTE|ESTAGIARIO|BOLSISTA|PEDAGOGO',\n",
    "    'Autônomo/Comércio': r'COMERCIANTE|AMBULANTE|TAXISTA|VENDEDOR|FEIRANTE|REPRESENTANTE COMERCIAL',\n",
    "    'Agropecuária': r'AGRICULTOR|PECUARISTA|PESCADOR|AVICULTOR|RURAL|FLORICULTOR|AGRONOMO|AGROPECUARISTA',\n",
    "    'Industrial': r'MECANICO|ELETRICISTA|OPERADOR|CONSTRUCAO|MARCENEIRO|INDUSTRIARIO|SERRALHEIRO|TECNIC',\n",
    "    'Justiça': r'ADVOGADO|DELEGADO|DEFENSOR|PROMOTOR|JUIZ|OFICIAL DE JUSTICA|TABELIAO|CARTORIO',\n",
    "    'Segurança': r'POLICIAL|MILITAR|VIGILANTE|SEGURANCA|BOMBEIRO',\n",
    "    'Cultura/Comunicação': r'MUSICO|ATOR|ARTESAO|JORNALISTA|ESCULTOR|PUBLICITARIO|FOTOGRAFO|LOCUTOR'\n",
    "}\n",
    "\n",
    "df['grupo_ocupacao'] = 'Outros'\n",
    "for grupo, regex in ocup_map.items():\n",
    "    df.loc[df['DS_OCUPACAO'].str.contains(regex, case=False, na=False), 'grupo_ocupacao'] = grupo\n",
    "df = pd.get_dummies(df, columns=['grupo_ocupacao'], prefix='oc', dtype=int)\n",
    "\n",
    "# Excluir variáveis auxiliares\n",
    "vars_to_drop = [\n",
    "    'DT_NASCIMENTO', 'SEXO', 'cliente', 'idade', 'UF_CADASTRO', 'CARTEIRA', 'CD_TIP_CTRA', \n",
    "    'NM_TIP_CTRA', 'EST_CIVIL', 'ESCOLAR', 'CD_PRFL_API', 'TX_DCR_PRFL', 'prfl_codigo', \n",
    "    'GRUPO_OCUPACAO', 'CD_NTZ_OCUPACAO', 'DS_NTZ_OCUPACAO', 'CD_OCUPACAO', \n",
    "    'DS_OCUPACAO', 'INVEST_EXT_RENDA_VARIAVEL', 'INVEST_NO_EXTERIOR', \n",
    "    'INVEST_EXTERIOR', 'INVEST_EXT_RENDA_FIXA'\n",
    "]\n",
    "df = df.drop(columns=[c for c in vars_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "# Variáveis com dados regionais\n",
    "dados_regionais = {\n",
    "    'regiao_norte': {'escolaridade': 9.2, 'renda': 2421.7, 'idh': 0.6847, 'pib': 33123},\n",
    "    'regiao_nordeste': {'escolaridade': 8.3, 'renda': 2078.0, 'idh': 0.6487, 'pib': 25401},\n",
    "    'regiao_sudeste': {'escolaridade': 10.0, 'renda': 3514.0, 'idh': 0.7537, 'pib': 63327},\n",
    "    'regiao_sul': {'escolaridade': 10.1, 'renda': 3423.7, 'idh': 0.7563, 'pib': 55942},\n",
    "    'regiao_centro-oeste': {'escolaridade': 10.1, 'renda': 3604.0, 'idh': 0.7533, 'pib': 65651},\n",
    "}\n",
    "\n",
    "for var in ['escolaridade_regiao', 'renda_regional', 'idh_regional', 'pib_percapita_regional']:\n",
    "    df[var] = np.nan\n",
    "\n",
    "for regiao, valores in dados_regionais.items():\n",
    "    mask = df[f'regiao_{regiao}'] == 1\n",
    "    df.loc[mask, 'escolaridade_regiao'] = valores['escolaridade']\n",
    "    df.loc[mask, 'renda_regional'] = valores['renda']\n",
    "    df.loc[mask, 'idh_regional'] = valores['idh']\n",
    "    df.loc[mask, 'pib_percapita_regional'] = valores['pib']\n",
    "\n",
    "# --- Variáveis Dependentes ---\n",
    "\n",
    "# Variável de diversificação\n",
    "df['soma_complex'] = df[['MULTIMERCADOS', 'RENDA_VARIAVEL', 'INVEST_ALTERNATIVOS', 'investimento_exterior']].sum(axis=1)\n",
    "df['soma_total'] = df[['RENDA_FIXA_POS_CDI', 'RENDA_FIXA_PRE', 'RENDA_FIXA_INFLACAO', 'MULTIMERCADOS', 'RENDA_VARIAVEL', 'INVEST_ALTERNATIVOS', 'investimento_exterior']].sum(axis=1)\n",
    "df['diver'] = df['soma_complex'] / df['soma_total']\n",
    "df['diver'] = df['diver'].fillna(0)\n",
    "# 'Diver' não pode ser maior que 1, então vamos garantir isso\n",
    "df.loc[df['diver'] > 1, 'diver'] = 1\n",
    "\n",
    "# Variável de complexidade financeira\n",
    "df['complex'] = (df['soma_complex'] > 0).astype(int)\n",
    "\n",
    "# --- Análises de Painel (Preparação) ---\n",
    "\n",
    "# Converter para painel: id_cliente e anomes\n",
    "# 'anomes' precisa ser um tipo de data para o PanelOLS\n",
    "df['anomes'] = pd.to_datetime(df['anomes'], format='%Y%m')\n",
    "df = df.set_index(['id_cliente', 'anomes'])\n",
    "df = df.sort_index()\n",
    "\n",
    "# Remover duplicatas (já feito com o `set_index` se `id_cliente` e `anomes` forem únicos para cada observação)\n",
    "df = df.loc[~df.index.duplicated(keep='first')]\n",
    "\n",
    "# Criar variáveis de variação e skewness (equivalente ao `xtset` do Stata)\n",
    "df['log_renda'] = np.log(df['renda'] + 1)\n",
    "df['delta_y'] = df.groupby(level='id_cliente')['log_renda'].diff()\n",
    "\n",
    "# Código para calcular o skewness (complexo, mas direto no pandas)\n",
    "df['ano'] = df.index.get_level_values('anomes').year\n",
    "df['regiao_codigo'] = df[['regiao_norte', 'regiao_nordeste', 'regiao_sudeste', 'regiao_sul', 'regiao_centro-oeste']].dot(\n",
    "    pd.Series([1, 2, 3, 4, 5], index=['regiao_norte', 'regiao_nordeste', 'regiao_sudeste', 'regiao_sul', 'regiao_centro-oeste'])\n",
    ")\n",
    "df['delta_y_anual'] = df.groupby(['id_cliente', 'ano'])['delta_y'].transform('mean')\n",
    "df['media_dy'] = df.groupby(['regiao_codigo', 'ano'])['delta_y_anual'].transform('mean')\n",
    "df['sd_dy'] = df.groupby(['regiao_codigo', 'ano'])['delta_y_anual'].transform('std')\n",
    "df['delta_y_pad'] = (df['delta_y_anual'] - df['media_dy']) / df['sd_dy']\n",
    "df['skew_aux'] = df['delta_y_pad']**3\n",
    "df['skew'] = df.groupby(['regiao_codigo', 'ano'])['skew_aux'].transform('mean')\n",
    "df['grupo_n'] = df.groupby(['regiao_codigo', 'ano'])['skew_aux'].transform('count')\n",
    "df.loc[df['grupo_n'] < 30, 'skew'] = np.nan\n",
    "df['skew_final'] = df.loc[df['ano'] > 2021, 'skew']\n",
    "df['skew_media_regional'] = df.groupby('regiao_codigo')['skew_final'].transform('mean')\n",
    "df['skew_proxy'] = df['skew'].fillna(df['skew_media_regional'])\n",
    "\n",
    "# Normalização com log natural (LN)\n",
    "df['ln_diver'] = np.log(df['diver'] + 0.01)\n",
    "# O `np.log` já lida com os valores zero ou missing corretamente\n",
    "\n",
    "df['ln_renda'] = np.log(df['renda_regional'].fillna(1))\n",
    "df['ln_ESC'] = np.log(df['escolaridade_regiao'].fillna(1))\n",
    "df['ln_IDH'] = np.log(df['idh_regional'].fillna(1))\n",
    "df['ln_PIB'] = np.log(df['pib_percapita_regional'].fillna(1))\n",
    "\n",
    "# Winsorização para controlar outliers\n",
    "# `mstats.winsorize` é a melhor tradução\n",
    "for var in ['ln_diver', 'ln_renda', 'ln_ESC', 'ln_IDH', 'ln_PIB']:\n",
    "    if var in df.columns:\n",
    "        df[f'{var}_w'] = mstats.winsorize(df[var], limits=(0.01, 0.01))\n",
    "\n",
    "# --- Início das Análises com Statsmodels e Linearmodels ---\n",
    "\n",
    "# Matriz de Correlação\n",
    "corr_vars = ['ln_diver_w', 'ln_renda_w', 'ln_ESC_w', 'ln_IDH_w', 'ln_PIB_w', 'idade_int', 'sexo_dummy', 'skew_proxy']\n",
    "corr_matrix = df[corr_vars].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.show()\n",
    "\n",
    "# Modelos com Pooled, FE e RE (usando a biblioteca `linearmodels`)\n",
    "# A biblioteca `linearmodels` é a melhor para regressões de painel em Python.\n",
    "# Lembre-se de definir as variáveis como \"entidades\" e \"tempo\" no `PanelOLS`.\n",
    "\n",
    "# Fórmula básica para os modelos\n",
    "formula = 'ln_diver_w ~ ln_renda_w + ln_IDH_w + sexo_dummy + idade_int'\n",
    "\n",
    "# Modelo Pooled\n",
    "mod_pooled = PooledOLS.from_formula(formula, data=df)\n",
    "res_pooled = mod_pooled.fit(cov_type='robust')\n",
    "print(\"\\nModelo Pooled:\")\n",
    "print(res_pooled)\n",
    "\n",
    "# Modelo de Efeitos Fixos\n",
    "mod_fe = PanelOLS.from_formula(formula + ' + EntityEffects', data=df)\n",
    "res_fe = mod_fe.fit(cov_type='clustered', cluster_entity=True)\n",
    "print(\"\\nModelo de Efeitos Fixos:\")\n",
    "print(res_fe)\n",
    "\n",
    "# Modelo de Efeitos Aleatórios\n",
    "mod_re = RandomEffects.from_formula(formula, data=df)\n",
    "res_re = mod_re.fit(cov_type='clustered', cluster_entity=True)\n",
    "print(\"\\nModelo de Efeitos Aleatórios:\")\n",
    "print(res_re)\n",
    "\n",
    "# Teste de Hausman (requer a biblioteca `hausman`, que é mais complexa de usar diretamente)\n",
    "# O mais simples é usar os resultados do `linearmodels` para tomar a decisão: se `fe` e `re` dão resultados muito diferentes, use `fe`.\n",
    "# O `linearmodels` tem um teste de Hausman integrado, mas a sintaxe pode ser um pouco diferente.\n",
    "# Você pode fazer o teste manualmente comparando os coeficientes:\n",
    "# hausman_stat = (res_fe.params - res_re.params).T @ np.linalg.inv(res_re.cov - res_fe.cov) @ (res_fe.params - res_re.params)\n",
    "\n",
    "# --- Regressões para as Hipóteses ---\n",
    "# H1 e H1a — Efeito da complexidade e contexto regional\n",
    "formula_h1 = 'ln_diver_w ~ complex + ln_ESC_w + ln_renda_w + regiao_norte + regiao_nordeste + regiao_sul + regiao_centro_oeste + sexo_dummy + idade_int + EntityEffects'\n",
    "mod_h1 = PanelOLS.from_formula(formula_h1, data=df)\n",
    "res_h1 = mod_h1.fit(cov_type='clustered', cluster_entity=True)\n",
    "print(\"\\nModelo H1 e H1a:\")\n",
    "print(res_h1)\n",
    "\n",
    "# H2 — Efeito do risco cíclico de renda\n",
    "formula_h2 = 'ln_diver_w ~ skew_proxy + ln_ESC_w + ln_renda_w + regiao_norte + regiao_nordeste + regiao_sul + regiao_centro_oeste + sexo_dummy + idade_int + EntityEffects'\n",
    "mod_h2 = PanelOLS.from_formula(formula_h2, data=df)\n",
    "res_h2 = mod_h2.fit(cov_type='clustered', cluster_entity=True)\n",
    "print(\"\\nModelo H2:\")\n",
    "print(res_h2)\n",
    "\n",
    "# H3 — Efeito do IDH em portfólios de alta renda\n",
    "df_alta_renda = df[df['renda'] > 20000]\n",
    "formula_h3 = 'ln_diver_w ~ ln_IDH_w + ln_renda_w + ln_ESC_w + regiao_norte + regiao_nordeste + regiao_sul + regiao_centro_oeste + sexo_dummy + idade_int + EntityEffects'\n",
    "mod_h3 = PanelOLS.from_formula(formula_h3, data=df_alta_renda)\n",
    "res_h3 = mod_h3.fit(cov_type='clustered', cluster_entity=True)\n",
    "print(\"\\nModelo H3:\")\n",
    "print(res_h3)\n",
    "\n",
    "# --- Estatísticas Descritivas ---\n",
    "# O método `describe()` é o mais comum para estatísticas descritivas\n",
    "print(\"\\nEstatísticas Descritivas:\")\n",
    "print(df[['diver', 'ln_diver_w', 'ln_renda_w', 'ln_ESC_w', 'ln_IDH_w', 'idade_int', 'sexo_dummy', 'complex', 'skew_proxy', 'perfil_conservador', 'perfil_moderado', 'perfil_arrojado']].describe())\n",
    "\n",
    "# --- Visualização de Dados (o poder do Python) ---\n",
    "# Gráfico de dispersão entre a diversificação e a renda, com linha de tendência\n",
    "sns.regplot(x='ln_renda_w', y='ln_diver_w', data=df)\n",
    "plt.title('Diversificação vs. Renda')\n",
    "plt.xlabel('Log da Renda (Winsorizado)')\n",
    "plt.ylabel('Log da Diversificação (Winsorizado)')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot da diversificação por grupo de ocupação\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='grupo_ocupacao', y='diver', data=df)\n",
    "plt.title('Diversificação por Grupo de Ocupação')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot da diversificação por perfil de investidor\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='perfil_grupo', y='diver', data=df)\n",
    "plt.title('Diversificação por Perfil do Investidor')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Análises Finais ---\")\n",
    "# O resto do seu script pode ser traduzido de forma similar. \n",
    "# Basta usar `PanelOLS` com os termos adicionais na fórmula."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
